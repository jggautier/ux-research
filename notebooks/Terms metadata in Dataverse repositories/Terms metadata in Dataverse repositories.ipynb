{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import plotly.express as px\n",
    "import statsmodels\n",
    "\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terms_metadata.tab file contains some basic metadata and the \"Terms\" metadata of all published versions of every dataset published in 49 known Dataverse repositories. \n",
    "\n",
    "Getting the data in terms_metadata.tab:\n",
    "- Download the 49 zipped files at https://doi.org/10.7910/DVN/DCDKZQ. Each zipped file contains the metadata of each published version of every dataset published in 49 known Dataverse repositories\n",
    "- Using your preferred method, move all JSON files into a single folder\n",
    "- Run the two scripts \"get_basic_metadata.py\" and \"get_terms_metadata.py\" at https://github.com/jggautier/dataverse_scripts/tree/master/get-dataverse-metadata/parse_metadata_fields with that folder as the input to get two CSV files, one containing the basic metadata of all datasets (publisher names, PIDs, publication dates, version numbers, etc), and one containing the Terms metadata for each version of each dataset.\n",
    "- Using your preferred method, retain from the basic_metadata file only the 'publisher', 'persistentUrl', 'datasetVersionId', 'majorVersionNumber', and 'minorVersionNumber' columns.\n",
    "- Using your preferred method, join both CSV files on their persistentUrl and datasetVersionId columns\n",
    "- Export the results as a .tab file (or export as a CSV and convert to TAB). Because of the Dataverse software's preference for .tab files, it's easier to work with if you plan to publish this data in a Dataverse repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('terms_metadata.tab', sep='\\t', na_filter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "print('Number of datasets: %s' % (len(pd.unique(data['persistentUrl']))))\n",
    "print('Number of dataset versions: %s' %(data.shape[0]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only metadata for the latest versions of each dataset\n",
    "latestversion = data.iloc[data.groupby('persistentUrl')['datasetVersionId'].agg(pd.Series.idxmax)].sort_values(by=['publisher'], inplace=False, ascending=True).reset_index(drop=True, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "print('Number of datasets: %s' % (len(pd.unique(latestversion['persistentUrl']))))\n",
    "print('Number of dataset versions: %s' %(latestversion.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latestversion.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any blank values with NaN\n",
    "latestversion = latestversion.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What are repositories putting in the their datasets' license fields?\n",
    "latestversion.license.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which datasets have the CC0 waiver or CCBY licenses in their Terms metadata?\n",
    "data_with_licenses = (\n",
    "    latestversion.query(\n",
    "        'termsOfUse.str.contains(\"CC0\")\\\n",
    "        or termsOfUse.str.contains(\"CCBY\")\\\n",
    "        or termsOfUse.str.contains(\"CC BY\")\\\n",
    "        or termsOfUse.str.contains(\"creative commons\", case = False)'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "print('Number of datasets: %s' % (len(pd.unique(data_with_licenses['persistentUrl']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of those datasets, which have any text in their other Terms metadata?\n",
    "data_with_licenses_and_other_terms = (\n",
    "    data_with_licenses.query(\n",
    "        'termsOfAccess == termsOfAccess or\\\n",
    "        availabilityStatus == availabilityStatus or\\\n",
    "        citationRequirements == citationRequirements or\\\n",
    "        conditions == conditions or\\\n",
    "        confidentialityDeclaration == confidentialityDeclaration or\\\n",
    "        contactForAccess == contactForAccess or\\\n",
    "        dataaccessPlace == dataaccessPlace or\\\n",
    "        depositorRequirements == depositorRequirements or\\\n",
    "        disclaimer == disclaimer or\\\n",
    "        originalArchive == originalArchive or\\\n",
    "        restrictions == restrictions or\\\n",
    "        sizeOfCollection == sizeOfCollection or\\\n",
    "        specialPermissions == specialPermissions or\\\n",
    "        studyCompletion == studyCompletion'\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "print('Number of datasets: %s' % (len(pd.unique(data_with_licenses_and_other_terms['persistentUrl']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_with_licenses_and_other_terms.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframe to CSV\n",
    "file = 'data_with_licenses_and_other_terms.csv'\n",
    "data_with_licenses_and_other_terms.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
