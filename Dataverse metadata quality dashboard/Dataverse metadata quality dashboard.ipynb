{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Plan\" data-toc-modified-id=\"Plan-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Plan</a></span></li><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-modules-and-load-functions\" data-toc-modified-id=\"Import-modules-and-load-functions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import modules and load functions</a></span></li><li><span><a href=\"#Get-dataverse-info\" data-toc-modified-id=\"Get-dataverse-info-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Get dataverse info</a></span></li><li><span><a href=\"#Get-aliases-of-any-sub-dataverses-in-the-given-dataverse\" data-toc-modified-id=\"Get-aliases-of-any-sub-dataverses-in-the-given-dataverse-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Get aliases of any sub-dataverses in the given dataverse</a></span></li><li><span><a href=\"#Get-dataset-info\" data-toc-modified-id=\"Get-dataset-info-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Get dataset info</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "For chosen dataverse:\n",
    "    - Show dataverse info:\n",
    "        - Show number of subdataverses, if any\n",
    "        - Show whether or not the (sub)dataverse has a description or tagline\n",
    "        - List metadatablocks of each (sub)dataverse\n",
    "        - List the facets set for each (sub)dataverse\n",
    "        - Verify that contact email address is valid for each (sub)dataverse\n",
    "        (see https://medium.com/@arjunsinghy96/verify-emails-over-socks-proxy-using-python-5589cb75c405\n",
    "        and https://github.com/Gardener-gg/email-verifier)\n",
    "    - Show dataset info\n",
    "        - Show number of datasets\n",
    "        - Show date of first published dataset\n",
    "        - Show date of most recently published or updated dataset\n",
    "        - Show average age of datasets\n",
    "        - Show average number of dataset versions\n",
    "        - Metadata (of latest published version of each dataset):\n",
    "            - Show average number of characters in the dataset descriptions\n",
    "                - List datasets with fewer than a certain number of characters in their descriptions\n",
    "            - List datasets with CC0 or Terms of Use metadata\n",
    "                - Versus number of datasets with no CC0 or TOU metadata\n",
    "                - List datasets with no CC0 or TOU metadata\n",
    "            - Show number of files that have no description metadata\n",
    "                - If a certain percentage of datasets have 1 or more files with no descriptions, list those datasets\n",
    "            - Related publication metadata\n",
    "                - Show number of datasets with related publication metadata\n",
    "                    - List datasets with no related publication metadata\n",
    "                - Show number of datasets with no PID in related publication metadata\n",
    "                    - List datasets with no PID in related publication metadata\n",
    "            - Show datasets that have no metadata for any non-citation metadatablocks enabled in the dataverse\n",
    "        - Data\n",
    "            - List count of each unique file format\n",
    "            - Show number of datasets with no files\n",
    "                - List datasets that have no files\n",
    "            - Show number of datasets with 1 or more uningested tabular files\n",
    "                - List datasets that contain 1 or more uningested tabular files\n",
    "            - Show number of datasets with 1 or more restricted files\n",
    "        - Contact emails\n",
    "            - Get number of datasets that have a contact email address that's different email from the dataverse contact email address\n",
    "            - Get unique list of contact email addresses and check if they're valid\n",
    "            - Show any datasets that have no valid email addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def improved_get(_dict, path, default=None):\n",
    "    for key in path.split('.'):\n",
    "        try:\n",
    "            _dict = _dict[key]\n",
    "        except KeyError:\n",
    "            return default\n",
    "    return _dict\n",
    "\n",
    "\n",
    "def list_to_string(list):\n",
    "    # Alphabetize list in case-insensitive way\n",
    "    list = sorted(list, key=lambda s: s.casefold())\n",
    "    # Change list to comma-separated string\n",
    "    delimiter = \",\"\n",
    "    string = delimiter.join(list)\n",
    "    return string\n",
    "\n",
    "\n",
    "def string_to_datetime(string):\n",
    "    newDatetime = datetime.strptime(string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "    return newDatetime\n",
    "\n",
    "# current_time = str.strftime('%Y.%m.%d_%H.%M.%S')\n",
    "# current_time = datetime.strftime('%Y-%m-%dT%H:%M:%S%z')\n",
    "# currentTime = datetime.now()\n",
    "currentTime = datetime.now(timezone.utc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataverse info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataverse server and alias from user - return error if there's no alias or if alias is the Root dataverse\n",
    "# server = 'https://demo.dataverse.org'\n",
    "# mainDataverseAlias = 'sefsef'\n",
    "server = 'https://dataverse.harvard.edu'\n",
    "mainDataverseAlias = 'dataverse-ux-research-dataverse'\n",
    "\n",
    "repositoryMetadataBlocksApi = '%s/api/v1/metadatablocks' % (server)\n",
    "response = requests.get(repositoryMetadataBlocksApi)\n",
    "repositoryMetadataBlocks = response.json()\n",
    "\n",
    "repositoryMetadataBlockNames = []\n",
    "for repositoryMetadataBlock in repositoryMetadataBlocks['data']:\n",
    "    repositoryMetadataBlockNames.append(repositoryMetadataBlock['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info from that dataverse: whether or not the dataverse has a description and/or tagline, metadatablocks enabled, facets enabled, validate contact email\n",
    "dataverseInfoApi = '%s/api/dataverses/%s' % (server, mainDataverseAlias)\n",
    "response = requests.get(dataverseInfoApi)\n",
    "dataverseMetadata = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataverse has a description\n",
      "Dataverse has no tagline\n",
      "Number of search facets used: 8\n",
      "Number of metadatablocks enabled (in addition to Citation): 3\n"
     ]
    }
   ],
   "source": [
    "if dataverseMetadata['status'] == 'ERROR':\n",
    "    print('No dataverse found. Is the dataverse published on Harvard Dataverse?')\n",
    "elif dataverseMetadata['status'] == 'OK':\n",
    "    dataverseDescription = improved_get(dataverseMetadata, 'data.description')\n",
    "    if dataverseDescription is not None:\n",
    "        print('Dataverse has a description')\n",
    "    else:\n",
    "        print('Dataverse has no description')\n",
    "\n",
    "    tagline = improved_get(dataverseMetadata, 'data.theme.tagline')\n",
    "    if tagline is not None:\n",
    "        print('Dataverse has a tagline')\n",
    "    else:\n",
    "        print('Dataverse has no tagline')\n",
    "\n",
    "#     contactEmails = []\n",
    "#     for contact in dataverseMetadata['data']['dataverseContacts']:\n",
    "#         contactEmails.append(contact['contactEmail'])\n",
    "#     print(contactEmails)\n",
    "\n",
    "    dataverseFacetsApi = '%s/api/dataverses/%s/facets' % (server, mainDataverseAlias)\n",
    "    response = requests.get(dataverseFacetsApi)\n",
    "    dataverseFacets = response.json()\n",
    "    facets = []\n",
    "    for facet in dataverseFacets['data']:\n",
    "        facets.append(facet)\n",
    "    print('Number of search facets used: %s' % (len(facets)))    \n",
    "\n",
    "#     # See if dataverse inherits its metadatablocks from its parent dataverse\n",
    "#     metadatablocksInheritedApi = '%s/api/dataverses/%s/metadatablocks/isRoot' % (server, dataverseAlias)\n",
    "#     response = requests.get(metadatablocksInheritedApi)\n",
    "#     metadatablocksInherited = response.json()\n",
    "#     print(metadatablocksInherited)\n",
    "    \n",
    "    # Get list of metadatablocks enabled in the dataverse\n",
    "    dataverseMetadatablocksList = []\n",
    "    dataverseMetadatablocksApi = '%s/api/dataverses/%s/metadatablocks' % (server, mainDataverseAlias)\n",
    "    response = requests.get(dataverseMetadatablocksApi)\n",
    "    dataverseMetadatablocks = response.json()\n",
    "    for dataverseMetadatablock in dataverseMetadatablocks['data']:\n",
    "        dataverseMetadatablock = dataverseMetadatablock['name']\n",
    "        dataverseMetadatablocksList.append(dataverseMetadatablock)\n",
    "    print('Number of metadatablocks enabled (in addition to Citation): %s' % (len(dataverseMetadatablocksList) - 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get aliases of any sub-dataverses in the given dataverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      "Found 1 dataverse and 2 subdataverses\n"
     ]
    }
   ],
   "source": [
    "mainDataverseInfoApi = '%s/api/dataverses/%s' % (server, mainDataverseAlias)\n",
    "response = requests.get(mainDataverseInfoApi)\n",
    "data = response.json()\n",
    "mainDataverseID = data['data']['id']\n",
    "\n",
    "dataverseIDs = [mainDataverseID]\n",
    "for dataverseID in dataverseIDs:\n",
    "\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    url = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    for i in data['data']:\n",
    "        if i['type'] == 'dataverse':\n",
    "            dataverseID = i['id']\n",
    "            dataverseIDs.extend([dataverseID])\n",
    "\n",
    "print('\\n\\nFound 1 dataverse and %s subdataverses' % (len(dataverseIDs) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetPID</th>\n",
       "      <th>dataverseName</th>\n",
       "      <th>dataverseUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doi:10.7910/DVN/QOU2CB</td>\n",
       "      <td>Dataverse Project UX Research</td>\n",
       "      <td>https://dataverse.harvard.edu/dataverse/datave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doi:10.7910/DVN/WS9OUR</td>\n",
       "      <td>Dataverse Project UX Research</td>\n",
       "      <td>https://dataverse.harvard.edu/dataverse/datave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doi:10.7910/DVN/DCDKZQ</td>\n",
       "      <td>Dataverse Project UX Research</td>\n",
       "      <td>https://dataverse.harvard.edu/dataverse/datave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doi:10.7910/DVN/ND1S3S</td>\n",
       "      <td>Harvard Dataverse 4.6 usability testing Dataverse</td>\n",
       "      <td>https://dataverse.harvard.edu/dataverse/harvar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doi:10.7910/DVN/2ZQQJI</td>\n",
       "      <td>Harvard Dataverse homepage research Dataverse</td>\n",
       "      <td>https://dataverse.harvard.edu/dataverse/homepa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datasetPID                                      dataverseName  \\\n",
       "0  doi:10.7910/DVN/QOU2CB                      Dataverse Project UX Research   \n",
       "1  doi:10.7910/DVN/WS9OUR                      Dataverse Project UX Research   \n",
       "2  doi:10.7910/DVN/DCDKZQ                      Dataverse Project UX Research   \n",
       "3  doi:10.7910/DVN/ND1S3S  Harvard Dataverse 4.6 usability testing Dataverse   \n",
       "4  doi:10.7910/DVN/2ZQQJI      Harvard Dataverse homepage research Dataverse   \n",
       "\n",
       "                                        dataverseUrl  \n",
       "0  https://dataverse.harvard.edu/dataverse/datave...  \n",
       "1  https://dataverse.harvard.edu/dataverse/datave...  \n",
       "2  https://dataverse.harvard.edu/dataverse/datave...  \n",
       "3  https://dataverse.harvard.edu/dataverse/harvar...  \n",
       "4  https://dataverse.harvard.edu/dataverse/homepa...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get PIDs of all published datasets in each of the dataverses\n",
    "datasetPIDs = []\n",
    "rowList = []\n",
    "for dataverseID in dataverseIDs:\n",
    "    getDataverseInfoApi = '%s/api/dataverses/%s' % (server, dataverseID)\n",
    "    response = requests.get(getDataverseInfoApi)\n",
    "    dataverseInfo = response.json()\n",
    "    dataverseName = dataverseInfo['data']['name']\n",
    "    dataverseAlias = dataverseInfo['data']['alias']\n",
    "\n",
    "    getDataverseContentsApi = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "    response = requests.get(getDataverseContentsApi)\n",
    "    dataverseContents = response.json()\n",
    "    for item in dataverseContents['data']:\n",
    "        if item['type'] == 'dataset':\n",
    "            datasetPID = item['persistentUrl'].replace('https://doi.org/', 'doi:')\n",
    "            datasetPIDs.append(datasetPID)\n",
    "            \n",
    "            newRow = {'datasetPID': datasetPID,\n",
    "                  'dataverseName': dataverseName,\n",
    "                  'dataverseUrl': '%s/dataverse/%s' % (server, dataverseAlias)\n",
    "                 }\n",
    "            rowList.append(dict(newRow))\n",
    "            \n",
    "print('Number of datasets: %s' % (len(datasetPIDs)))\n",
    "\n",
    "datasetDataverseInfoDF = pd.DataFrame(rowList)\n",
    "datasetDataverseInfoDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe for dataset info: date of publication, the release date of the latest version, number of versions\n",
    "\n",
    "_Getting this info can be slow. For example, getting the info of ~375 datasets might take 45 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 of 5 (doi:10.7910/DVN/2ZQQJI)\r"
     ]
    }
   ],
   "source": [
    "# Create list of file types that Dataverse can convert to .tab files during ingest\n",
    "uningestedFileTypes = ['application/x-rlang-transport', 'application/x-stata-13', 'application/x-spss-por',\n",
    "                      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'text/csv', 'text/tsv',\n",
    "                      'application/x-spss-sav', 'text/comma-separated-values', 'application/x-stata',\n",
    "                      'application/x-stata-14']\n",
    "\n",
    "rowList = []\n",
    "datasetCount = 0\n",
    "for datasetPID in datasetPIDs:\n",
    "    getAllVersionsApi = '%s/api/datasets/:persistentId/versions?persistentId=%s' % (server, datasetPID)\n",
    "    response = requests.get(getAllVersionsApi)\n",
    "    datasetVersions = response.json()\n",
    "    \n",
    "    # Get only datasets with metadata (exclude responses with no values in 'data' key, e.g. deaccessioned datasets)\n",
    "    if datasetVersions['status'] == 'OK' and len(datasetVersions['data']) > 0:\n",
    "        \n",
    "        # Get metadata of latest version\n",
    "        latestDatasetVersion = datasetVersions['data'][0]\n",
    "        \n",
    "        # Get index location of first dataset version\n",
    "        firstVersion = len(datasetVersions['data']) - 1\n",
    "\n",
    "        publicationDate = string_to_datetime(datasetVersions['data'][firstVersion]['releaseTime'])\n",
    "        latestReleaseDate = string_to_datetime(latestDatasetVersion['releaseTime'])\n",
    "        \n",
    "        # Get age of dataset from today's date\n",
    "        delta = currentTime - publicationDate\n",
    "        ageOfDataset = delta.days\n",
    "        \n",
    "        # Get number of days since last update\n",
    "        delta = currentTime - latestReleaseDate\n",
    "        ageOfLastUpdate = delta.days\n",
    "        \n",
    "        # Get length of description text\n",
    "        descriptionLength = 0\n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'dsDescription':\n",
    "                for i in field['value']:\n",
    "                    descriptionLength = descriptionLength + len(i['dsDescriptionValue']['value'])\n",
    "\n",
    "        # See whether CC0 or Terms of Use metadata exists\n",
    "        license = latestDatasetVersion['license']\n",
    "        try:\n",
    "            termsOfUse = latestDatasetVersion['termsOfUse']\n",
    "            termsOfUse = True\n",
    "        except KeyError:\n",
    "            termsOfUse = False\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            termsOfAccess = latestDatasetVersion['termsOfAccess']\n",
    "            termsOfAccess = True\n",
    "        except KeyError:\n",
    "            termsOfAccess = False\n",
    "\n",
    "        if license != 'CC0' and termsOfUse == False:\n",
    "            termsExist = False\n",
    "        else:\n",
    "            termsExist = True\n",
    "\n",
    "        # Get info about related publication metadata\n",
    "        relPubCount = 0\n",
    "        relPubPIDCount = 0\n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'publication':\n",
    "                for value in field['value']:\n",
    "                    relPubCount += 1\n",
    "                    try:\n",
    "                        publicationIDType = value['publicationIDType']\n",
    "                        publicationIDNumber = value['publicationIDNumber']\n",
    "                        relPubPIDCount += 1\n",
    "                    except KeyError:\n",
    "                        relPubPIDCount = relPubPIDCount\n",
    "            else:\n",
    "                relPubCount = relPubCount\n",
    "        \n",
    "        # Show metadatablocks whose fields are used by the dataset\n",
    "        usedMetadataBlocks = []\n",
    "        for repositoryMetadataBlockName in repositoryMetadataBlockNames:\n",
    "            try:\n",
    "                fieldCount = len(latestDatasetVersion['metadataBlocks'][repositoryMetadataBlockName]['fields'])\n",
    "                if fieldCount > 0:\n",
    "                    usedMetadataBlocks.append(repositoryMetadataBlockName)\n",
    "            except KeyError:\n",
    "                usedMetadataBlocks = usedMetadataBlocks\n",
    "        if len(usedMetadataBlocks) == 0:\n",
    "            usedMetadataBlocks = ''\n",
    "        else:\n",
    "            usedMetadataBlocks = list_to_string(usedMetadataBlocks)\n",
    "        \n",
    "        # Get number of files\n",
    "        numberOfFiles = len(latestDatasetVersion['files'])\n",
    "\n",
    "        # Get file info\n",
    "        noFileDescriptionCount = 0\n",
    "        contentType = []\n",
    "        ingestedTabFilesCount = 0\n",
    "        uningestedTabFilesCount = 0\n",
    "        restrictedFilesCount = 0\n",
    "        fileTags = []\n",
    "        for file in latestDatasetVersion['files']:            \n",
    "            if 'description' in file:\n",
    "                noFileDescriptionCount = noFileDescriptionCount\n",
    "            else:\n",
    "                noFileDescriptionCount += 1\n",
    "            contentType.append(file['dataFile']['contentType'])\n",
    "            if file['restricted'] == True:\n",
    "                restrictedFilesCount += 1\n",
    "            if file['dataFile']['contentType'] in uningestedFileTypes:\n",
    "                uningestedTabFilesCount += 1\n",
    "            if file['dataFile']['contentType'] == 'text/tab-separated-values':\n",
    "                ingestedTabFilesCount += 1\n",
    "            try:\n",
    "                for tags in file['categories']:\n",
    "                    fileTags.append(tags)\n",
    "            except KeyError:\n",
    "                fileTags = fileTags\n",
    "\n",
    "        if len(fileTags) == 0:\n",
    "            fileTagsExist = False\n",
    "        else:\n",
    "            fileTagsExist = True\n",
    "\n",
    "        if len(contentType) == 0:\n",
    "            uniqueContentTypes = 'NA'\n",
    "        else:\n",
    "            uniqueContentTypes = list_to_string(list(set(contentType)))\n",
    "\n",
    "        # Create dictionary\n",
    "        newRow = {'datasetPID': datasetPID,\n",
    "                  'datasetPIDUrl' : datasetPID.replace('doi:', 'https://doi.org/'),\n",
    "                  'numberOfVersions': len(datasetVersions['data']),\n",
    "                  'numberOfMajorVersions': latestDatasetVersion['versionNumber'],\n",
    "                  'publicationDate': publicationDate,\n",
    "                  'latestReleaseDate': latestReleaseDate,\n",
    "                  'ageOfDataset(Days)': ageOfDataset,\n",
    "                  'ageOfLastUpdate(Days)': ageOfLastUpdate,\n",
    "                  'descriptionLenth': descriptionLength,\n",
    "                  'termsExist': termsExist,\n",
    "                  'license': license,\n",
    "                  'termsOfUseExists': termsOfUse,\n",
    "                  'termsOfAccessExists': termsOfAccess,\n",
    "                  'relPubCount': relPubCount,\n",
    "                  'relPubPIDCount': relPubPIDCount,\n",
    "                  'usedMetadataBlocks': usedMetadataBlocks,\n",
    "                  'numberOfFiles': numberOfFiles,\n",
    "                  'noFileDescriptionCount': noFileDescriptionCount,\n",
    "                  'fileTagsExist': fileTagsExist,\n",
    "                  'uniqueContentTypes': uniqueContentTypes,\n",
    "                  'ingestedTabFilesCount': ingestedTabFilesCount,\n",
    "                  'uningestedTabFilesCount': uningestedTabFilesCount,\n",
    "                  'restrictedFilesCount': restrictedFilesCount\n",
    "                 }\n",
    "        rowList.append(dict(newRow))\n",
    "        datasetCount += 1\n",
    "        print('%s of %s (%s)' % (datasetCount, len(datasetPIDs), datasetPID), end='\\r', flush=True)\n",
    "        \n",
    "if len(datasetPIDs) != datasetCount:\n",
    "    print('The metadata of %s dataset(s) could not be retrieved' % (len(datasetPIDs) - datasetCount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetPID</th>\n",
       "      <th>datasetPIDUrl</th>\n",
       "      <th>numberOfVersions</th>\n",
       "      <th>numberOfMajorVersions</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>latestReleaseDate</th>\n",
       "      <th>ageOfDataset(Days)</th>\n",
       "      <th>ageOfLastUpdate(Days)</th>\n",
       "      <th>descriptionLenth</th>\n",
       "      <th>termsExist</th>\n",
       "      <th>...</th>\n",
       "      <th>relPubCount</th>\n",
       "      <th>relPubPIDCount</th>\n",
       "      <th>usedMetadataBlocks</th>\n",
       "      <th>numberOfFiles</th>\n",
       "      <th>noFileDescriptionCount</th>\n",
       "      <th>fileTagsExist</th>\n",
       "      <th>uniqueContentTypes</th>\n",
       "      <th>ingestedTabFilesCount</th>\n",
       "      <th>uningestedTabFilesCount</th>\n",
       "      <th>restrictedFilesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doi:10.7910/DVN/QOU2CB</td>\n",
       "      <td>https://doi.org/10.7910/DVN/QOU2CB</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-19 16:38:28+00:00</td>\n",
       "      <td>2020-10-19 17:13:14+00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>872</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>citation</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>application/x-ipynb+json,text/plain,text/tab-s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doi:10.7910/DVN/WS9OUR</td>\n",
       "      <td>https://doi.org/10.7910/DVN/WS9OUR</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-09 00:37:49+00:00</td>\n",
       "      <td>2020-10-27 17:59:53+00:00</td>\n",
       "      <td>1115</td>\n",
       "      <td>1</td>\n",
       "      <td>413</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>citation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>application/vnd.openxmlformats-officedocument....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doi:10.7910/DVN/DCDKZQ</td>\n",
       "      <td>https://doi.org/10.7910/DVN/DCDKZQ</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-12-21 18:48:52+00:00</td>\n",
       "      <td>2020-09-25 14:11:48+00:00</td>\n",
       "      <td>312</td>\n",
       "      <td>33</td>\n",
       "      <td>3651</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>citation</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>application/zip,text/tab-separated-values</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doi:10.7910/DVN/ND1S3S</td>\n",
       "      <td>https://doi.org/10.7910/DVN/ND1S3S</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-04 22:56:39+00:00</td>\n",
       "      <td>2020-04-20 13:45:38+00:00</td>\n",
       "      <td>1392</td>\n",
       "      <td>191</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>citation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>text/tab-separated-values</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doi:10.7910/DVN/2ZQQJI</td>\n",
       "      <td>https://doi.org/10.7910/DVN/2ZQQJI</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-03 22:07:29+00:00</td>\n",
       "      <td>2019-02-12 17:46:31+00:00</td>\n",
       "      <td>1393</td>\n",
       "      <td>624</td>\n",
       "      <td>270</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>citation</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>application/vnd.openxmlformats-officedocument....</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               datasetPID                       datasetPIDUrl  \\\n",
       "0  doi:10.7910/DVN/QOU2CB  https://doi.org/10.7910/DVN/QOU2CB   \n",
       "1  doi:10.7910/DVN/WS9OUR  https://doi.org/10.7910/DVN/WS9OUR   \n",
       "2  doi:10.7910/DVN/DCDKZQ  https://doi.org/10.7910/DVN/DCDKZQ   \n",
       "3  doi:10.7910/DVN/ND1S3S  https://doi.org/10.7910/DVN/ND1S3S   \n",
       "4  doi:10.7910/DVN/2ZQQJI  https://doi.org/10.7910/DVN/2ZQQJI   \n",
       "\n",
       "   numberOfVersions  numberOfMajorVersions           publicationDate  \\\n",
       "0                 3                      2 2020-10-19 16:38:28+00:00   \n",
       "1                19                      3 2017-10-09 00:37:49+00:00   \n",
       "2                13                      9 2019-12-21 18:48:52+00:00   \n",
       "3                13                      1 2017-01-04 22:56:39+00:00   \n",
       "4                25                      4 2017-01-03 22:07:29+00:00   \n",
       "\n",
       "          latestReleaseDate  ageOfDataset(Days)  ageOfLastUpdate(Days)  \\\n",
       "0 2020-10-19 17:13:14+00:00                   9                      9   \n",
       "1 2020-10-27 17:59:53+00:00                1115                      1   \n",
       "2 2020-09-25 14:11:48+00:00                 312                     33   \n",
       "3 2020-04-20 13:45:38+00:00                1392                    191   \n",
       "4 2019-02-12 17:46:31+00:00                1393                    624   \n",
       "\n",
       "   descriptionLenth  termsExist  ... relPubCount  relPubPIDCount  \\\n",
       "0               872        True  ...           0               0   \n",
       "1               413        True  ...           1               1   \n",
       "2              3651        True  ...           0               0   \n",
       "3               173       False  ...           0               0   \n",
       "4               270       False  ...           0               0   \n",
       "\n",
       "   usedMetadataBlocks  numberOfFiles  noFileDescriptionCount fileTagsExist  \\\n",
       "0            citation              3                       3         False   \n",
       "1            citation              1                       0          True   \n",
       "2            citation             50                      50         False   \n",
       "3            citation              1                       0         False   \n",
       "4            citation              3                       0         False   \n",
       "\n",
       "                                  uniqueContentTypes  ingestedTabFilesCount  \\\n",
       "0  application/x-ipynb+json,text/plain,text/tab-s...                      1   \n",
       "1  application/vnd.openxmlformats-officedocument....                      0   \n",
       "2          application/zip,text/tab-separated-values                      1   \n",
       "3                          text/tab-separated-values                      1   \n",
       "4  application/vnd.openxmlformats-officedocument....                      0   \n",
       "\n",
       "   uningestedTabFilesCount restrictedFilesCount  \n",
       "0                        0                    0  \n",
       "1                        1                    0  \n",
       "2                        0                    0  \n",
       "3                        0                    1  \n",
       "4                        2                    2  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetInfoDF = pd.DataFrame(rowList)\n",
    "datasetInfoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Save dataframe to CSV\n",
    "csvFileName = '%s_datasets_2.csv' % (dataverseAlias)\n",
    "df.to_csv(csvFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['datasetPID'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-499ebc9ce1cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# For each dataframe, set the indexes (or the common columns across the dataframes to join on)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datasetPID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Merge all dataframes and save to the 'merged' variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4551\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['datasetPID'] are in the columns\""
     ]
    }
   ],
   "source": [
    "dataframes = [datasetDataverseInfoDF, datasetInfoDF]\n",
    "\n",
    "# For each dataframe, set the indexes (or the common columns across the dataframes to join on)\n",
    "for dataframe in dataframes:\n",
    "    dataframe.set_index(['datasetPID'], inplace=True)\n",
    "\n",
    "# Merge all dataframes and save to the 'merged' variable\n",
    "merged = reduce(lambda left, right: left.join(right, how='outer'), dataframes)\n",
    "merged.reset_index(drop=False, inplace=True)\n",
    "merged\n",
    "# merged = pd.concat(dataframes, join='inner', ignore_index=True)\n",
    "# merged\n",
    "# pd.concat(objs, axis=0, join='outer', ignore_index=False, keys=None,\n",
    "#           levels=None, names=None, verify_integrity=False, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show date of first published dataset\n",
    "# publicationDates = df['publicationDate']\n",
    "# firstPublicationDate = publicationDates.min()\n",
    "\n",
    "# # Show date of most recently published or updated dataset\n",
    "# latestReleaseDates = df['latestReleaseDate']\n",
    "# lastReleaseDate = latestReleaseDates.min()\n",
    "\n",
    "# # Show age of most recently published or updated dataset\n",
    "# ageOfLastUpdates = df['ageOfLastUpdate']\n",
    "# ageOfLastUpdate = ageOfLastUpdates.min()\n",
    "\n",
    "# # Show average age of datasets\n",
    "# ageOfDatasets = df['ageOfDataset(Days)']\n",
    "# averageAge = ageOfDatasets.mean()\n",
    "\n",
    "# # Show average number of dataset versions\n",
    "# numberOfVersions = df['numberOfVersions']\n",
    "# averageNumberOfVersions = numberOfVersions.mean()\n",
    "\n",
    "# # Create list of datasets with fewer than a certain number of characters in their descriptions\n",
    "# lowDescriptionCount = df[df['descriptionLenth'] < 20]\n",
    "# lowDescriptionCount = lowDescriptionCount['datasetPID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List count of each unique file format"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
