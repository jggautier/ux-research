{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Plan\" data-toc-modified-id=\"Plan-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Plan</a></span></li><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-modules-and-load-functions\" data-toc-modified-id=\"Import-modules-and-load-functions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import modules and load functions</a></span></li><li><span><a href=\"#Get-dataverse-info\" data-toc-modified-id=\"Get-dataverse-info-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Get dataverse info</a></span></li><li><span><a href=\"#Get-aliases-of-any-sub-dataverses-in-the-given-dataverse\" data-toc-modified-id=\"Get-aliases-of-any-sub-dataverses-in-the-given-dataverse-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Get aliases of any sub-dataverses in the given dataverse</a></span></li><li><span><a href=\"#Get-dataset-info\" data-toc-modified-id=\"Get-dataset-info-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Get dataset info</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "For chosen dataverse:\n",
    "    - Show dataverse info:\n",
    "        - Show number of subdataverses, if any\n",
    "        - Show whether or not the (sub)dataverse has a description or tagline\n",
    "        - List metadatablocks of each (sub)dataverse\n",
    "        - List the facets set for each (sub)dataverse\n",
    "        - Verify that contact email address is valid for each (sub)dataverse\n",
    "        (see https://medium.com/@arjunsinghy96/verify-emails-over-socks-proxy-using-python-5589cb75c405\n",
    "        and https://github.com/Gardener-gg/email-verifier)\n",
    "    - Show dataset info\n",
    "        - Show number of datasets\n",
    "        - Show date of first published dataset\n",
    "        - Show date of most recently published or updated dataset\n",
    "        - Show average age of datasets\n",
    "        - Show average number of dataset versions\n",
    "        - Metadata (of latest published version of each dataset):\n",
    "            - Show average number of characters in the dataset descriptions\n",
    "                - List datasets with fewer than a certain number of characters in their descriptions\n",
    "            - List datasets with CC0 or Terms of Use metadata\n",
    "                - Versus number of datasets with no CC0 or TOU metadata\n",
    "                - List datasets with no CC0 or TOU metadata\n",
    "            - Show number of files that have no description metadata\n",
    "                - If a certain percentage of datasets have 1 or more files with no descriptions, list those datasets\n",
    "            - Related publication metadata\n",
    "                - Show number of datasets with related publication metadata\n",
    "                    - List datasets with no related publication metadata\n",
    "                - Show number of datasets with no PID in related publication metadata\n",
    "                    - List datasets with no PID in related publication metadata\n",
    "            - Show datasets that have no metadata for any non-citation metadatablocks enabled in the dataverse\n",
    "        - Data\n",
    "            - List count of each unique file format\n",
    "            - Show number of datasets with no files\n",
    "                - List datasets that have no files\n",
    "            - Show number of datasets with 1 or more uningested tabular files\n",
    "                - List datasets that contain 1 or more uningested tabular files\n",
    "            - Show number of datasets with 1 or more restricted files\n",
    "        - Contact emails\n",
    "            - Get number of datasets that have a contact email address that's different email from the dataverse contact email address\n",
    "            - Get unique list of contact email addresses and check if they're valid\n",
    "            - Show any datasets that have no valid email addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def improved_get(_dict, path, default=None):\n",
    "    for key in path.split('.'):\n",
    "        try:\n",
    "            _dict = _dict[key]\n",
    "        except KeyError:\n",
    "            return default\n",
    "    return _dict\n",
    "\n",
    "\n",
    "def list_to_string(list):\n",
    "    # Alphabetize list in case-insensitive way\n",
    "    list = sorted(list, key=lambda s: s.casefold())\n",
    "\n",
    "    # Change list to comma-separated string\n",
    "    delimiter = \",\"\n",
    "    string = delimiter.join(list)\n",
    "    return string\n",
    "\n",
    "\n",
    "def string_to_list(string): \n",
    "    li = list(string.split(\",\")) \n",
    "    return li\n",
    "\n",
    "\n",
    "def string_to_datetime(string):\n",
    "    newDatetime = datetime.strptime(string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "    return newDatetime\n",
    "\n",
    "\n",
    "currentTime = datetime.now(timezone.utc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataverse info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataverse server and alias from user - return error if there's no alias or if alias is the Root dataverse\n",
    "# server = 'https://demo.dataverse.org'\n",
    "# mainDataverseAlias = 'sefsef'\n",
    "server = 'https://dataverse.harvard.edu'\n",
    "mainDataverseAlias = 'mit'\n",
    "\n",
    "repositoryMetadataBlocksApi = '%s/api/v1/metadatablocks' % (server)\n",
    "response = requests.get(repositoryMetadataBlocksApi)\n",
    "repositoryMetadataBlocks = response.json()\n",
    "\n",
    "repositoryMetadataBlockNames = []\n",
    "for repositoryMetadataBlock in repositoryMetadataBlocks['data']:\n",
    "    repositoryMetadataBlockNames.append(repositoryMetadataBlock['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info from that dataverse: whether or not the dataverse has a description and/or tagline, metadatablocks enabled, facets enabled, validate contact email\n",
    "dataverseInfoApi = '%s/api/dataverses/%s' % (server, mainDataverseAlias)\n",
    "response = requests.get(dataverseInfoApi)\n",
    "dataverseMetadata = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataverse description exists: True\n",
      "Dataverse tagline exists: True\n",
      "Number of search facets used: 9\n",
      "Number of metadatablocks enabled (in addition to Citation): 2\n",
      "\t['citation', 'socialscience', 'geospatial']\n"
     ]
    }
   ],
   "source": [
    "if dataverseMetadata['status'] == 'ERROR':\n",
    "    print('No dataverse found. Is the dataverse published on Harvard Dataverse?')\n",
    "elif dataverseMetadata['status'] == 'OK':\n",
    "    if 'description' in dataverseMetadata['data']:\n",
    "        dataverseMetadataExists = True\n",
    "    else:\n",
    "        dataverseMetadataExists = False\n",
    "    print('Dataverse description exists: %s' % (dataverseMetadataExists))\n",
    "\n",
    "    if 'theme' in dataverseMetadata['data'] and 'tagline' in dataverseMetadata['data']['theme']:\n",
    "        taglineExists = True\n",
    "    else:\n",
    "        taglineExists = False\n",
    "    print('Dataverse tagline exists: %s' % (taglineExists))\n",
    "\n",
    "#     contactEmails = []\n",
    "#     for contact in dataverseMetadata['data']['dataverseContacts']:\n",
    "#         contactEmails.append(contact['contactEmail'])\n",
    "#     print(contactEmails)\n",
    "\n",
    "    dataverseFacetsApi = '%s/api/dataverses/%s/facets' % (server, mainDataverseAlias)\n",
    "    response = requests.get(dataverseFacetsApi)\n",
    "    dataverseFacets = response.json()\n",
    "    facets = []\n",
    "    for facet in dataverseFacets['data']:\n",
    "        facets.append(facet)\n",
    "    print('Number of search facets used: %s' % (len(facets)))    \n",
    "\n",
    "#     # See if dataverse inherits its metadatablocks from its parent dataverse\n",
    "#     metadatablocksInheritedApi = '%s/api/dataverses/%s/metadatablocks/isRoot' % (server, dataverseAlias)\n",
    "#     response = requests.get(metadatablocksInheritedApi)\n",
    "#     metadatablocksInherited = response.json()\n",
    "#     print(metadatablocksInherited)\n",
    "    \n",
    "    # Get list of metadatablocks enabled in the dataverse\n",
    "    dataverseMetadatablocksList = []\n",
    "    dataverseMetadatablocksApi = '%s/api/dataverses/%s/metadatablocks' % (server, mainDataverseAlias)\n",
    "    response = requests.get(dataverseMetadatablocksApi)\n",
    "    dataverseMetadatablocks = response.json()\n",
    "    for dataverseMetadatablock in dataverseMetadatablocks['data']:\n",
    "        dataverseMetadatablock = dataverseMetadatablock['name']\n",
    "        dataverseMetadatablocksList.append(dataverseMetadatablock)\n",
    "    print('Number of metadatablocks enabled (in addition to Citation): %s' % (len(dataverseMetadatablocksList) - 1))\n",
    "    print('\\t%s' % (dataverseMetadatablocksList))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get aliases of any sub-dataverses in the given dataverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Found 1 dataverse and 0 subdataverses\n"
     ]
    }
   ],
   "source": [
    "mainDataverseInfoApi = '%s/api/dataverses/%s' % (server, mainDataverseAlias)\n",
    "response = requests.get(mainDataverseInfoApi)\n",
    "data = response.json()\n",
    "mainDataverseID = data['data']['id']\n",
    "\n",
    "dataverseIDs = [mainDataverseID]\n",
    "for dataverseID in dataverseIDs:\n",
    "\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    url = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    for i in data['data']:\n",
    "        if i['type'] == 'dataverse':\n",
    "            dataverseID = i['id']\n",
    "            dataverseIDs.extend([dataverseID])\n",
    "\n",
    "print('\\n\\nFound 1 dataverse and %s subdataverses' % (len(dataverseIDs) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Number of datasets: 3\n"
     ]
    }
   ],
   "source": [
    "# Get PIDs of all published datasets in each of the dataverses\n",
    "datasetPIDs = []\n",
    "rowList = []\n",
    "for dataverseID in dataverseIDs:\n",
    "    getDataverseInfoApi = '%s/api/dataverses/%s' % (server, dataverseID)\n",
    "    response = requests.get(getDataverseInfoApi)\n",
    "    dataverseInfo = response.json()\n",
    "    dataverseName = dataverseInfo['data']['name']\n",
    "    dataverseAlias = dataverseInfo['data']['alias']\n",
    "\n",
    "    getDataverseContentsApi = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "    response = requests.get(getDataverseContentsApi)\n",
    "    dataverseContents = response.json()\n",
    "    for item in dataverseContents['data']:\n",
    "        if item['type'] == 'dataset':\n",
    "            datasetPID = item['persistentUrl'].replace('https://doi.org/', 'doi:')\n",
    "            datasetPIDs.append(datasetPID)\n",
    "            \n",
    "            newRow = {'datasetPID': datasetPID,\n",
    "                  'dataverseName': dataverseName,\n",
    "                  'dataverseUrl': '%s/dataverse/%s' % (server, dataverseAlias)\n",
    "                 }\n",
    "            rowList.append(dict(newRow))\n",
    "            \n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "print('\\nNumber of datasets: %s' % (len(datasetPIDs)))\n",
    "\n",
    "datasetDataverseInfoDF = pd.DataFrame(rowList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datasetPIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe for dataset info: date of publication, the release date of the latest version, number of versions\n",
    "\n",
    "_Getting this info can be slow. For example, getting the info of ~375 datasets might take 45 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 of 3 (doi:10.70122/FK2/ZYUGHH)\r"
     ]
    }
   ],
   "source": [
    "# Create list of file types that Dataverse can convert to .tab files during ingest\n",
    "uningestedFileTypes = ['application/x-rlang-transport', 'application/x-stata-13', 'application/x-spss-por',\n",
    "                      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'text/csv', 'text/tsv',\n",
    "                      'application/x-spss-sav', 'text/comma-separated-values', 'application/x-stata',\n",
    "                      'application/x-stata-14']\n",
    "\n",
    "rowList = []\n",
    "datasetCount = 0\n",
    "for datasetPID in datasetPIDs:\n",
    "    getAllVersionsApi = '%s/api/datasets/:persistentId/versions?persistentId=%s' % (server, datasetPID)\n",
    "    response = requests.get(getAllVersionsApi)\n",
    "    datasetVersions = response.json()\n",
    "    \n",
    "    # Get only datasets with metadata (exclude responses with no values in 'data' key, e.g. deaccessioned datasets)\n",
    "    if datasetVersions['status'] == 'OK' and len(datasetVersions['data']) > 0:\n",
    "        \n",
    "        # Get metadata of latest version\n",
    "        latestDatasetVersion = datasetVersions['data'][0]\n",
    "        \n",
    "        # Get index location of first dataset version\n",
    "        firstVersion = len(datasetVersions['data']) - 1\n",
    "\n",
    "        publicationDate = string_to_datetime(datasetVersions['data'][firstVersion]['releaseTime'])\n",
    "        latestReleaseDate = string_to_datetime(latestDatasetVersion['releaseTime'])\n",
    "        \n",
    "        # Get age of dataset from today's date\n",
    "        delta = currentTime - publicationDate\n",
    "        ageOfDataset = delta.days\n",
    "        \n",
    "        # Get number of days since last update\n",
    "        delta = currentTime - latestReleaseDate\n",
    "        ageOfLastUpdate = delta.days\n",
    "        if ageOfLastUpdate < 0:\n",
    "            ageOfLastUpdate = 0\n",
    "        \n",
    "        # Get length of description text\n",
    "        descriptionLength = 0\n",
    "        \n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'dsDescription':\n",
    "                # \"N/A\" is the value assigned there was no description given (pre Dataverse 4)\n",
    "                if len(field['value']) == 1 and field['value'][0]['dsDescriptionValue']['value'] == 'N/A':\n",
    "                    descriptionLength = 0\n",
    "                else:\n",
    "                    for i in field['value']:\n",
    "                        descriptionLength = descriptionLength + len(i['dsDescriptionValue']['value'])\n",
    "\n",
    "        # See whether CC0 or Terms of Use metadata exists\n",
    "        license = latestDatasetVersion.get('license', 'None')\n",
    "\n",
    "        if 'termsOfUse' in latestDatasetVersion:\n",
    "            termsOfUse = True\n",
    "        else:\n",
    "            termsOfUse = False\n",
    "            \n",
    "        if 'termsOfAccess' in latestDatasetVersion:\n",
    "            termsOfAccess = True\n",
    "        else:\n",
    "            termsOfAccess = False\n",
    "\n",
    "        if license != 'CC0' and termsOfUse == False:\n",
    "            termsExist = False\n",
    "        else:\n",
    "            termsExist = True\n",
    "\n",
    "        # Get info about related publication metadata\n",
    "        relPubCount = 0\n",
    "        relPubPIDCount = 0\n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'publication':\n",
    "                for value in field['value']:\n",
    "                    relPubCount += 1\n",
    "                    if 'publicationIDType' and 'publicationIDNumber' in value:\n",
    "                        relPubPIDCount += 1\n",
    "        \n",
    "        # Show metadatablocks whose fields are used by the dataset\n",
    "        usedMetadataBlocks = []\n",
    "        for repositoryMetadataBlockName in repositoryMetadataBlockNames:\n",
    "            try:\n",
    "                fieldCount = len(latestDatasetVersion['metadataBlocks'][repositoryMetadataBlockName]['fields'])\n",
    "                if fieldCount > 0:\n",
    "                    usedMetadataBlocks.append(repositoryMetadataBlockName)\n",
    "            except KeyError:\n",
    "                usedMetadataBlocks = usedMetadataBlocks\n",
    "        if len(usedMetadataBlocks) == 0:\n",
    "            usedMetadataBlocks = ''\n",
    "        else:\n",
    "            usedMetadataBlocks = list_to_string(usedMetadataBlocks)\n",
    "        \n",
    "        # Get number of files\n",
    "        numberOfFiles = len(latestDatasetVersion['files'])\n",
    "\n",
    "        # Get file info\n",
    "        noFileDescriptionCount = 0\n",
    "        contentType = []\n",
    "        ingestedTabFilesCount = 0\n",
    "        uningestedTabFilesCount = 0\n",
    "        restrictedFilesCount = 0\n",
    "        fileTags = []\n",
    "        for file in latestDatasetVersion['files']:            \n",
    "            if 'description' in file:\n",
    "                noFileDescriptionCount = noFileDescriptionCount\n",
    "            else:\n",
    "                noFileDescriptionCount += 1\n",
    "            contentType.append(file['dataFile']['contentType'])\n",
    "            if file['restricted'] == True:\n",
    "                restrictedFilesCount += 1\n",
    "            if file['dataFile']['contentType'] in uningestedFileTypes:\n",
    "                uningestedTabFilesCount += 1\n",
    "            if file['dataFile']['contentType'] == 'text/tab-separated-values':\n",
    "                ingestedTabFilesCount += 1\n",
    "            try:\n",
    "                for tags in file['categories']:\n",
    "                    fileTags.append(tags)\n",
    "            except KeyError:\n",
    "                fileTags = fileTags\n",
    "\n",
    "        tabularDataFileCount = uningestedTabFilesCount + ingestedTabFilesCount\n",
    "\n",
    "        if len(fileTags) == 0:\n",
    "            fileTagsExist = False\n",
    "        else:\n",
    "            fileTagsExist = True\n",
    "\n",
    "        if len(contentType) == 0:\n",
    "            uniqueContentTypes = 'NA'\n",
    "        else:\n",
    "            uniqueContentTypes = list_to_string(list(set(contentType)))\n",
    "\n",
    "        # Create dictionary\n",
    "        newRow = {'datasetPID': datasetPID,\n",
    "                  'datasetPIDUrl' : datasetPID.replace('doi:', 'https://doi.org/'),\n",
    "                  'numberOfVersions': len(datasetVersions['data']),\n",
    "                  'numberOfMajorVersions': latestDatasetVersion['versionNumber'],\n",
    "                  'publicationDate': publicationDate,\n",
    "                  'latestReleaseDate': latestReleaseDate,\n",
    "                  'ageOfDataset(Days)': ageOfDataset,\n",
    "                  'ageOfLastUpdate(Days)': ageOfLastUpdate,\n",
    "                  'descriptionLenth': descriptionLength,\n",
    "                  'termsExist': termsExist,\n",
    "                  'license': license,\n",
    "                  'termsOfUseExists': termsOfUse,\n",
    "                  'termsOfAccessExists': termsOfAccess,\n",
    "                  'relPubCount': relPubCount,\n",
    "                  'relPubPIDCount': relPubPIDCount,\n",
    "                  'usedMetadataBlocks': usedMetadataBlocks,\n",
    "                  'numberOfFiles': numberOfFiles,\n",
    "                  'noFileDescriptionCount': noFileDescriptionCount,\n",
    "                  'fileTagsExist': fileTagsExist,\n",
    "                  'uniqueContentTypes': uniqueContentTypes,\n",
    "                  'tabularDataFileCount': ingestedTabFilesCount + uningestedTabFilesCount,\n",
    "                  'ingestedTabFilesCount': ingestedTabFilesCount,\n",
    "                  'uningestedTabFilesCount': uningestedTabFilesCount,\n",
    "                  'restrictedFilesCount': restrictedFilesCount\n",
    "                 }\n",
    "        rowList.append(dict(newRow))\n",
    "        datasetCount += 1\n",
    "        print('%s of %s (%s)' % (datasetCount, len(datasetPIDs), datasetPID), end='\\r', flush=True)\n",
    "        \n",
    "if len(datasetPIDs) != datasetCount:\n",
    "    print('The metadata of %s dataset(s) could not be retrieved' % (len(datasetPIDs) - datasetCount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetInfoDF = pd.DataFrame(rowList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [datasetDataverseInfoDF, datasetInfoDF]\n",
    "\n",
    "# For each dataframe, set the indexes (or the common columns across the dataframes to join on)\n",
    "for dataframe in dataframes:\n",
    "    dataframe.set_index(['datasetPID'], inplace=True)\n",
    "\n",
    "# Merge both dataframes and save to the 'merged' variable\n",
    "report = reduce(lambda left, right: left.join(right, how='outer'), dataframes)\n",
    "\n",
    "# Reset index\n",
    "report.reset_index(drop=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetPID</th>\n",
       "      <th>dataverseName</th>\n",
       "      <th>dataverseUrl</th>\n",
       "      <th>datasetPIDUrl</th>\n",
       "      <th>numberOfVersions</th>\n",
       "      <th>numberOfMajorVersions</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>latestReleaseDate</th>\n",
       "      <th>ageOfDataset(Days)</th>\n",
       "      <th>ageOfLastUpdate(Days)</th>\n",
       "      <th>...</th>\n",
       "      <th>relPubPIDCount</th>\n",
       "      <th>usedMetadataBlocks</th>\n",
       "      <th>numberOfFiles</th>\n",
       "      <th>noFileDescriptionCount</th>\n",
       "      <th>fileTagsExist</th>\n",
       "      <th>uniqueContentTypes</th>\n",
       "      <th>tabularDataFileCount</th>\n",
       "      <th>ingestedTabFilesCount</th>\n",
       "      <th>uningestedTabFilesCount</th>\n",
       "      <th>restrictedFilesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doi:10.70122/FK2/HZTO03</td>\n",
       "      <td>Julian Gautier (SU) Dataverse</td>\n",
       "      <td>https://demo.dataverse.org/dataverse/sefsef</td>\n",
       "      <td>https://doi.org/10.70122/FK2/HZTO03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 19:48:40+00:00</td>\n",
       "      <td>2020-10-26 03:44:39+00:00</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>citation,geospatial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doi:10.70122/FK2/CMFTOD</td>\n",
       "      <td>Julian Gautier (SU) Dataverse</td>\n",
       "      <td>https://demo.dataverse.org/dataverse/sefsef</td>\n",
       "      <td>https://doi.org/10.70122/FK2/CMFTOD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-14 20:07:47+00:00</td>\n",
       "      <td>2020-10-14 20:07:47+00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>citation</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>image/jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doi:10.70122/FK2/ZYUGHH</td>\n",
       "      <td>Julian Gautier (SU) Dataverse</td>\n",
       "      <td>https://demo.dataverse.org/dataverse/sefsef</td>\n",
       "      <td>https://doi.org/10.70122/FK2/ZYUGHH</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-17 16:08:53+00:00</td>\n",
       "      <td>2020-10-29 03:16:38+00:00</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>astrophysics,biomedical,citation,geospatial,so...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>image/jpeg,image/png,text/tab-separated-values</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datasetPID                  dataverseName  \\\n",
       "0  doi:10.70122/FK2/HZTO03  Julian Gautier (SU) Dataverse   \n",
       "1  doi:10.70122/FK2/CMFTOD  Julian Gautier (SU) Dataverse   \n",
       "2  doi:10.70122/FK2/ZYUGHH  Julian Gautier (SU) Dataverse   \n",
       "\n",
       "                                  dataverseUrl  \\\n",
       "0  https://demo.dataverse.org/dataverse/sefsef   \n",
       "1  https://demo.dataverse.org/dataverse/sefsef   \n",
       "2  https://demo.dataverse.org/dataverse/sefsef   \n",
       "\n",
       "                         datasetPIDUrl  numberOfVersions  \\\n",
       "0  https://doi.org/10.70122/FK2/HZTO03                 3   \n",
       "1  https://doi.org/10.70122/FK2/CMFTOD                 1   \n",
       "2  https://doi.org/10.70122/FK2/ZYUGHH                16   \n",
       "\n",
       "   numberOfMajorVersions           publicationDate         latestReleaseDate  \\\n",
       "0                      1 2020-08-04 19:48:40+00:00 2020-10-26 03:44:39+00:00   \n",
       "1                      1 2020-10-14 20:07:47+00:00 2020-10-14 20:07:47+00:00   \n",
       "2                      5 2020-09-17 16:08:53+00:00 2020-10-29 03:16:38+00:00   \n",
       "\n",
       "   ageOfDataset(Days)  ageOfLastUpdate(Days)  ...  relPubPIDCount  \\\n",
       "0                  86                      3  ...               0   \n",
       "1                  15                     15  ...               0   \n",
       "2                  42                      0  ...               1   \n",
       "\n",
       "                                  usedMetadataBlocks numberOfFiles  \\\n",
       "0                                citation,geospatial             0   \n",
       "1                                           citation             2   \n",
       "2  astrophysics,biomedical,citation,geospatial,so...             3   \n",
       "\n",
       "   noFileDescriptionCount  fileTagsExist  \\\n",
       "0                       0          False   \n",
       "1                       2          False   \n",
       "2                       2           True   \n",
       "\n",
       "                               uniqueContentTypes  tabularDataFileCount  \\\n",
       "0                                              NA                     0   \n",
       "1                                      image/jpeg                     0   \n",
       "2  image/jpeg,image/png,text/tab-separated-values                     1   \n",
       "\n",
       "  ingestedTabFilesCount  uningestedTabFilesCount  restrictedFilesCount  \n",
       "0                     0                        0                     0  \n",
       "1                     0                        0                     0  \n",
       "2                     1                        0                     0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export report to CSV\n",
    "file = '%s_%s.csv' % (mainDataverseAlias, currentTime)\n",
    "report.to_csv(file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.read_csv('mit_datasets.csv', na_filter = False)\n",
    "datasetCount = len(report.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((len(report[(report['ingestedTabFilesCount']!=0)]))+(len(report[(report['uningestedTabFilesCount']!=0)])))/datasetCount*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of metadatablocks used by all datasets\n",
    "allUsedMetadataBlocks = []\n",
    "for i in report['usedMetadataBlocks']:\n",
    "    allUsedMetadataBlocks.extend(list(i.split(\",\")))\n",
    "\n",
    "# Deduplicate, alphabetize and change list to string\n",
    "allUsedMetadataBlocks = list_to_string(list(set(allUsedMetadataBlocks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in report['uniqueContentTypes']:\n",
    "#     print('%s: %s' % (i, type(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of uniqueContentTypes used by all datasets\n",
    "allContentTypes = []\n",
    "for i in report['uniqueContentTypes']:\n",
    "    if i != 'NA':\n",
    "        allContentTypes.extend(list(i.split(\",\")))\n",
    "\n",
    "# Deduplicate, alphabetize and change list to string\n",
    "# allContentTypes = list_to_string(list(set(allContentTypes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary\n",
    "summaryDict = {\n",
    "    'Summary': {\n",
    "        '0': 'Has description',\n",
    "        '1': 'Has tagline',\n",
    "        '2': 'Number of search facets',\n",
    "        '3': 'Metadatablocks enabled',\n",
    "        '4': 'Dataset count',\n",
    "        '5': 'Versions (avg # of major and minor versions)',\n",
    "        '6': 'Major versions (average #)',\n",
    "        '7': 'Description length (avg # of characters)',\n",
    "        '8': 'CC0 datasets (% of total datasets)',\n",
    "        '9': 'Age of datasets (average)',\n",
    "        '10': 'No terms (% of datasets with no terms metadata)',\n",
    "        '11': 'Related pub metadata (% of datasets with rel pub metadata)',\n",
    "        '12': 'Related pub PIDs (% of datasets with rel pub PIDs)',\n",
    "        '13': 'Metadatablocks used (list)',\n",
    "        '14': 'No files (# of datasets with no files)',\n",
    "        '15': 'File descriptions (% of datasets with 1 or more file descriptions)',\n",
    "        '16': 'File tags (% of datasets with 1 or more file tags)',\n",
    "        '17': 'Unique file types (count)',\n",
    "        '18': 'Tabular data (% of datasets with tabular data) ',\n",
    "        '19': 'Tabular data ingest successes (% of datasets with tabular data that has been ingested)',\n",
    "        '20': 'Public files (% of unrestricted files)'\n",
    "    },\n",
    "    mainDataverseAlias: {\n",
    "        '0': dataverseMetadataExists,\n",
    "        '1': taglineExists,\n",
    "        '2': len(facets),\n",
    "        '3': len(dataverseMetadatablocksList) - 1,\n",
    "        '4': datasetCount,\n",
    "        '5': round(report['numberOfVersions'].mean(), 2),\n",
    "        '6': round(report['numberOfMajorVersions'].mean(), 2),\n",
    "        '7': round(report['descriptionLenth'].mean(), 2),\n",
    "        '8': round((len(report[(report['license']=='CC0')])/datasetCount)*100, 2),\n",
    "        '9': round(report['ageOfDataset(Days)'].mean(), 2),\n",
    "        '10': round(((~report['termsExist']).values.sum())/datasetCount*100, 2),\n",
    "        '11': round(len(report[(report['relPubCount']!=0)])/datasetCount*100, 2),\n",
    "        '12': round(len(report[(report['relPubPIDCount']!=0)])/datasetCount*100, 2),\n",
    "        '13': allUsedMetadataBlocks,\n",
    "        '14': len(report[(report['numberOfFiles']==0)]),\n",
    "        '15': round(len(report[(report['noFileDescriptionCount']!=0)])/datasetCount*100, 2),\n",
    "        '16': ((report['fileTagsExist']).values.sum())/datasetCount*100,\n",
    "        '17': len(set(allContentTypes)),\n",
    "        '18': round(((len(report[(report['ingestedTabFilesCount']!=0)]))+(len(report[(report['uningestedTabFilesCount']!=0)])))/len(report[(report['numberOfFiles']!=0)])*100, 2),\n",
    "        '19': round(len(report[(report['ingestedTabFilesCount']!=0)])/((len(report[(report['ingestedTabFilesCount']!=0)]))+(len(report[(report['uningestedTabFilesCount']!=0)])))*100, 2),\n",
    "        '20': round(((report['numberOfFiles'].sum() - report['restrictedFilesCount'].sum())/report['numberOfFiles'].sum())*100, 2)\n",
    "    }\n",
    "}\n",
    "\n",
    "# # Show average age of datasets\n",
    "# ageOfDatasets = report['ageOfDataset(Days)'].mean()\n",
    "# averageDatasetAge = ageOfDatasets.mean()\n",
    "\n",
    "# # Show average number of dataset versions\n",
    "# numberOfVersions = report['numberOfVersions'].mean()\n",
    "# averageNumberOfVersions = numberOfVersions.mean()\n",
    "\n",
    "# # Create list of datasets with fewer than a certain number of characters in their descriptions\n",
    "# lowDescriptionCount = df[df['descriptionLenth'] < 20]\n",
    "# lowDescriptionCount = lowDescriptionCount['datasetPID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDF = pd.DataFrame(summaryDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>mit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has description</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Has tagline</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of search facets</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metadatablocks enabled</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset count</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Versions (avg # of major and minor versions)</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Major versions (average #)</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Description length (avg # of characters)</td>\n",
       "      <td>339.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC0 datasets (% of total datasets)</td>\n",
       "      <td>7.05882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Age of datasets (average)</td>\n",
       "      <td>1527.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No terms (% of datasets with no terms metadata)</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Related pub metadata (% of datasets with rel p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Related pub PIDs (% of datasets with rel pub P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Metadatablocks used (list)</td>\n",
       "      <td>citation,geospatial,socialscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>No files (# of datasets with no files)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>File descriptions (% of datasets with 1 or mor...</td>\n",
       "      <td>41.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>File tags (% of datasets with 1 or more file t...</td>\n",
       "      <td>37.6471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unique file types (count)</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tabular data (% of datasets with tabular data)</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tabular data ingest successes (% of datasets w...</td>\n",
       "      <td>72.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Public files (% of unrestricted files)</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Summary  \\\n",
       "0                                     Has description   \n",
       "1                                         Has tagline   \n",
       "2                             Number of search facets   \n",
       "3                              Metadatablocks enabled   \n",
       "4                                       Dataset count   \n",
       "5        Versions (avg # of major and minor versions)   \n",
       "6                          Major versions (average #)   \n",
       "7            Description length (avg # of characters)   \n",
       "8                  CC0 datasets (% of total datasets)   \n",
       "9                           Age of datasets (average)   \n",
       "10    No terms (% of datasets with no terms metadata)   \n",
       "11  Related pub metadata (% of datasets with rel p...   \n",
       "12  Related pub PIDs (% of datasets with rel pub P...   \n",
       "13                         Metadatablocks used (list)   \n",
       "14             No files (# of datasets with no files)   \n",
       "15  File descriptions (% of datasets with 1 or mor...   \n",
       "16  File tags (% of datasets with 1 or more file t...   \n",
       "17                          Unique file types (count)   \n",
       "18    Tabular data (% of datasets with tabular data)    \n",
       "19  Tabular data ingest successes (% of datasets w...   \n",
       "20             Public files (% of unrestricted files)   \n",
       "\n",
       "                                  mit  \n",
       "0                                True  \n",
       "1                                True  \n",
       "2                                   9  \n",
       "3                                   2  \n",
       "4                                  85  \n",
       "5                                3.55  \n",
       "6                                1.71  \n",
       "7                              339.08  \n",
       "8                             7.05882  \n",
       "9                             1527.98  \n",
       "10                               4.71  \n",
       "11                                  0  \n",
       "12                                  0  \n",
       "13  citation,geospatial,socialscience  \n",
       "14                                  5  \n",
       "15                              41.18  \n",
       "16                            37.6471  \n",
       "17                                 26  \n",
       "18                                 55  \n",
       "19                              72.73  \n",
       "20                                2.7  "
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaryDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export report to CSV\n",
    "file = '%s_summary_%s.csv' % (mainDataverseAlias, currentTime)\n",
    "summaryDF.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
